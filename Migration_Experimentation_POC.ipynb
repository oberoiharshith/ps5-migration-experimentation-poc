{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c036b8ce",
   "metadata": {},
   "source": [
    "# PS4 → PS5 Migration Experimentation POC (Synthetic)\n",
    "\n",
    "**Goal:** Demonstrate how to design, analyze, and communicate an experimentation + causal inference readout for a migration campaign.\n",
    "\n",
    "This notebook uses a **synthetic dataset** generated to resemble a realistic product marketing experiment:\n",
    "- Stratified randomization\n",
    "- Conversion + revenue outcomes\n",
    "- Guardrail metrics\n",
    "- Variance reduction (CUPED)\n",
    "- Bayesian analysis\n",
    "- Sequential testing / early stopping\n",
    "\n",
    "> Replace the synthetic data with real tables in production. The analysis pattern stays the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1a01c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "      <th>platform_tenure_days</th>\n",
       "      <th>last_30d_sessions</th>\n",
       "      <th>last_90d_spend</th>\n",
       "      <th>ps_plus_member</th>\n",
       "      <th>pre_30d_spend</th>\n",
       "      <th>spend_tier</th>\n",
       "      <th>engagement_tier</th>\n",
       "      <th>stratum</th>\n",
       "      <th>treatment</th>\n",
       "      <th>ps5_purchase_30d</th>\n",
       "      <th>revenue_60d</th>\n",
       "      <th>post_30d_sessions</th>\n",
       "      <th>unsubscribe_flag</th>\n",
       "      <th>optout_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DE</td>\n",
       "      <td>2691</td>\n",
       "      <td>12</td>\n",
       "      <td>16.53</td>\n",
       "      <td>0</td>\n",
       "      <td>15.66</td>\n",
       "      <td>S1_low</td>\n",
       "      <td>E4_vhigh</td>\n",
       "      <td>S1_low_E4_vhigh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51.29</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>3223</td>\n",
       "      <td>8</td>\n",
       "      <td>43.08</td>\n",
       "      <td>1</td>\n",
       "      <td>12.27</td>\n",
       "      <td>S2_mid</td>\n",
       "      <td>E2_mid</td>\n",
       "      <td>S2_mid_E2_mid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FR</td>\n",
       "      <td>2099</td>\n",
       "      <td>16</td>\n",
       "      <td>34.08</td>\n",
       "      <td>1</td>\n",
       "      <td>10.39</td>\n",
       "      <td>S2_mid</td>\n",
       "      <td>E4_vhigh</td>\n",
       "      <td>S2_mid_E4_vhigh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113.93</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>UK</td>\n",
       "      <td>1528</td>\n",
       "      <td>6</td>\n",
       "      <td>76.28</td>\n",
       "      <td>0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>S4_vhigh</td>\n",
       "      <td>E1_low</td>\n",
       "      <td>S4_vhigh_E1_low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>98.47</td>\n",
       "      <td>0</td>\n",
       "      <td>27.99</td>\n",
       "      <td>S4_vhigh</td>\n",
       "      <td>E2_mid</td>\n",
       "      <td>S4_vhigh_E2_mid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.02</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country  platform_tenure_days  last_30d_sessions  last_90d_spend  \\\n",
       "0        1      DE                  2691                 12           16.53   \n",
       "1        2      US                  3223                  8           43.08   \n",
       "2        3      FR                  2099                 16           34.08   \n",
       "3        4      UK                  1528                  6           76.28   \n",
       "4        5      US                    46                  8           98.47   \n",
       "\n",
       "   ps_plus_member  pre_30d_spend spend_tier engagement_tier          stratum  \\\n",
       "0               0          15.66     S1_low        E4_vhigh  S1_low_E4_vhigh   \n",
       "1               1          12.27     S2_mid          E2_mid    S2_mid_E2_mid   \n",
       "2               1          10.39     S2_mid        E4_vhigh  S2_mid_E4_vhigh   \n",
       "3               0          27.88   S4_vhigh          E1_low  S4_vhigh_E1_low   \n",
       "4               0          27.99   S4_vhigh          E2_mid  S4_vhigh_E2_mid   \n",
       "\n",
       "   treatment  ps5_purchase_30d  revenue_60d  post_30d_sessions  \\\n",
       "0          1                 0        51.29                  9   \n",
       "1          1                 0         4.86                 13   \n",
       "2          1                 1       113.93                 22   \n",
       "3          1                 0         0.00                  9   \n",
       "4          1                 0        56.02                  9   \n",
       "\n",
       "   unsubscribe_flag  optout_flag  \n",
       "0                 0            0  \n",
       "1                 0            0  \n",
       "2                 0            0  \n",
       "3                 0            0  \n",
       "4                 0            0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "DATA_PATH = \"data/migration_experiment_synthetic.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae83790",
   "metadata": {},
   "source": [
    "## 1) Quick sanity checks\n",
    "\n",
    "We confirm:\n",
    "- Treatment/control split is ~50/50 overall and within strata\n",
    "- Basic covariates are balanced\n",
    "- Guardrails are not exploding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37783fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment\n",
       "1    0.50008\n",
       "0    0.49992\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall split\n",
    "df[\"treatment\"].value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b836fa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(treatment            0     1  treat_rate\n",
       " stratum                                 \n",
       " S2_mid_E1_low     1951  1951    0.500000\n",
       " S2_mid_E2_mid     1749  1749    0.500000\n",
       " S2_mid_E3_high    1426  1426    0.500000\n",
       " S2_mid_E4_vhigh   1124  1124    0.500000\n",
       " S3_high_E1_low    1954  1954    0.500000\n",
       " S3_high_E2_mid    1741  1741    0.500000\n",
       " S3_high_E4_vhigh  1150  1150    0.500000\n",
       " S4_vhigh_E1_low   1947  1947    0.500000\n",
       " S1_low_E1_low     1962  1963    0.500127\n",
       " S4_vhigh_E2_mid   1771  1772    0.500141,\n",
       " count    16.000000\n",
       " mean      0.500086\n",
       " std       0.000092\n",
       " min       0.500000\n",
       " 25%       0.500000\n",
       " 50%       0.500064\n",
       " 75%       0.500178\n",
       " max       0.500216\n",
       " Name: treat_rate, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split by stratum (spot check)\n",
    "check = (df.groupby([\"stratum\",\"treatment\"])[\"user_id\"].count()\n",
    "         .unstack(fill_value=0))\n",
    "check[\"treat_rate\"] = check[1] / (check[0] + check[1])\n",
    "check.sort_values(\"treat_rate\").head(10), check[\"treat_rate\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33beebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>SMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre_30d_spend</td>\n",
       "      <td>-1.638387e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ps_plus_member</td>\n",
       "      <td>1.640815e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>platform_tenure_days</td>\n",
       "      <td>1.207920e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last_90d_spend</td>\n",
       "      <td>-9.867435e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last_30d_sessions</td>\n",
       "      <td>9.292302e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature           SMD\n",
       "4         pre_30d_spend -1.638387e-02\n",
       "3        ps_plus_member  1.640815e-03\n",
       "0  platform_tenure_days  1.207920e-03\n",
       "2        last_90d_spend -9.867435e-04\n",
       "1     last_30d_sessions  9.292302e-07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariate balance (standardized mean differences)\n",
    "def smd(x_t, x_c):\n",
    "    x_t = np.asarray(x_t); x_c = np.asarray(x_c)\n",
    "    return (x_t.mean() - x_c.mean()) / np.sqrt(0.5*(x_t.var(ddof=1)+x_c.var(ddof=1)))\n",
    "\n",
    "covars = [\"platform_tenure_days\",\"last_30d_sessions\",\"last_90d_spend\",\"ps_plus_member\",\"pre_30d_spend\"]\n",
    "out = []\n",
    "t = df[df.treatment==1]\n",
    "c = df[df.treatment==0]\n",
    "for col in covars:\n",
    "    out.append((col, smd(t[col], c[col])))\n",
    "pd.DataFrame(out, columns=[\"feature\",\"SMD\"]).sort_values(\"SMD\", key=lambda s: s.abs(), ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22211b29",
   "metadata": {},
   "source": [
    "## 2) Primary metric: 30-day PS5 conversion\n",
    "\n",
    "We estimate:\n",
    "- Conversion rates by group\n",
    "- Absolute and relative lift\n",
    "- 95% CI\n",
    "- Frequentist p-value (two-proportion z test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7487e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'control_rate': np.float64(0.1751480236837894),\n",
       " 'treatment_rate': np.float64(0.21048632218844984),\n",
       " 'absolute_lift': np.float64(0.03533829850466044),\n",
       " 'relative_lift': np.float64(0.20176247360038657),\n",
       " 'z': np.float64(10.014733579854493),\n",
       " 'p_value': np.float64(0.0),\n",
       " '95%_CI_abs_lift': (np.float64(0.028429199164298577),\n",
       "  np.float64(0.04224739784502231))}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conversion_summary(d):\n",
    "    n = len(d)\n",
    "    x = d[\"ps5_purchase_30d\"].sum()\n",
    "    rate = x/n\n",
    "    return n, x, rate\n",
    "\n",
    "n_c, x_c, p_c = conversion_summary(df[df.treatment==0])\n",
    "n_t, x_t, p_t = conversion_summary(df[df.treatment==1])\n",
    "\n",
    "abs_lift = p_t - p_c\n",
    "rel_lift = abs_lift / p_c\n",
    "\n",
    "# Two-proportion z test\n",
    "p_pool = (x_c + x_t) / (n_c + n_t)\n",
    "se_pool = np.sqrt(p_pool*(1-p_pool)*(1/n_c + 1/n_t))\n",
    "z = abs_lift / se_pool\n",
    "p_value = 2*(1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "# Wald CI on difference (ok for large n)\n",
    "se_diff = np.sqrt(p_c*(1-p_c)/n_c + p_t*(1-p_t)/n_t)\n",
    "ci = (abs_lift - 1.96*se_diff, abs_lift + 1.96*se_diff)\n",
    "\n",
    "{\n",
    "    \"control_rate\": p_c,\n",
    "    \"treatment_rate\": p_t,\n",
    "    \"absolute_lift\": abs_lift,\n",
    "    \"relative_lift\": rel_lift,\n",
    "    \"z\": z,\n",
    "    \"p_value\": p_value,\n",
    "    \"95%_CI_abs_lift\": ci\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1703f",
   "metadata": {},
   "source": [
    "## 3) Guardrails\n",
    "\n",
    "We check whether treatment meaningfully increases unsubscribe / opt-out rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc4481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsubscribe_flag {'control': 0.0043206913106096975, 'treatment': 0.0074388097904335305, 'diff': 0.003118118479823833}\n",
      "optout_flag {'control': 0.005880940950552089, 'treatment': 0.011238201887697969, 'diff': 0.00535726093714588}\n"
     ]
    }
   ],
   "source": [
    "def rate(col):\n",
    "    g = df.groupby(\"treatment\")[col].mean()\n",
    "    return float(g.loc[0]), float(g.loc[1]), float(g.loc[1]-g.loc[0])\n",
    "\n",
    "for col in [\"unsubscribe_flag\",\"optout_flag\"]:\n",
    "    c_rate, t_rate, diff = rate(col)\n",
    "    print(col, {\"control\": c_rate, \"treatment\": t_rate, \"diff\": diff})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e96d9c4",
   "metadata": {},
   "source": [
    "## 4) Variance reduction with CUPED (on revenue)\n",
    "\n",
    "CUPED uses a **pre-period metric** correlated with the outcome to reduce variance.\n",
    "\n",
    "Here:\n",
    "- Outcome = `revenue_60d`\n",
    "- Covariate = `pre_30d_spend`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04421a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_revenue_diff': np.float64(9.406110424092432),\n",
       " 'raw_95%_CI': (np.float64(8.458525858204244), np.float64(10.353694989980621)),\n",
       " 'raw_SE': np.float64(0.48346151320825986),\n",
       " 'cuped_revenue_diff': np.float64(9.511686330685087),\n",
       " 'cuped_95%_CI': (np.float64(8.570941792773485),\n",
       "  np.float64(10.45243086859669)),\n",
       " 'cuped_SE': np.float64(0.4799717030161237),\n",
       " 'SE_reduction_factor': np.float64(0.9927816173639599)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"revenue_60d\"].values\n",
    "x = df[\"pre_30d_spend\"].values\n",
    "\n",
    "theta = np.cov(y, x, ddof=1)[0,1] / np.var(x, ddof=1)\n",
    "y_cuped = y - theta*(x - x.mean())\n",
    "\n",
    "df2 = df.copy()\n",
    "df2[\"revenue_60d_cuped\"] = y_cuped\n",
    "\n",
    "def diff_in_means(d, col):\n",
    "    t = d[d.treatment==1][col].values\n",
    "    c = d[d.treatment==0][col].values\n",
    "    diff = t.mean() - c.mean()\n",
    "    # Welch t CI\n",
    "    se = np.sqrt(t.var(ddof=1)/len(t) + c.var(ddof=1)/len(c))\n",
    "    ci = (diff - 1.96*se, diff + 1.96*se)\n",
    "    return diff, ci, se\n",
    "\n",
    "raw_diff, raw_ci, raw_se = diff_in_means(df2, \"revenue_60d\")\n",
    "cuped_diff, cuped_ci, cuped_se = diff_in_means(df2, \"revenue_60d_cuped\")\n",
    "\n",
    "{\n",
    "    \"raw_revenue_diff\": raw_diff,\n",
    "    \"raw_95%_CI\": raw_ci,\n",
    "    \"raw_SE\": raw_se,\n",
    "    \"cuped_revenue_diff\": cuped_diff,\n",
    "    \"cuped_95%_CI\": cuped_ci,\n",
    "    \"cuped_SE\": cuped_se,\n",
    "    \"SE_reduction_factor\": cuped_se/raw_se\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f3a97",
   "metadata": {},
   "source": [
    "## 5) Bayesian readout (conversion)\n",
    "\n",
    "Bayesian analysis answers questions like:\n",
    "\n",
    "- “Given the data, what's the probability treatment is better than control?”\n",
    "- “What's the probability lift is at least X?”\n",
    "\n",
    "For conversion we can use a **Beta-Binomial** model:\n",
    "- Prior: Beta(1, 1) (uniform)\n",
    "- Posterior: Beta(1 + conversions, 1 + nonconversions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df61b76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P(lift > 0)': 1.0,\n",
       " 'P(lift > 1pp absolute)': 1.0,\n",
       " '95%_credible_interval_lift': (0.028422807315936934, 0.042239109446691694)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "a0, b0 = 1, 1  # prior\n",
    "\n",
    "post_c = (a0 + x_c, b0 + (n_c - x_c))\n",
    "post_t = (a0 + x_t, b0 + (n_t - x_t))\n",
    "\n",
    "# Monte Carlo to estimate distribution of lift\n",
    "draws = 200000\n",
    "pc = beta.rvs(post_c[0], post_c[1], size=draws, random_state=42)\n",
    "pt = beta.rvs(post_t[0], post_t[1], size=draws, random_state=43)\n",
    "lift = pt - pc\n",
    "\n",
    "prob_lift_gt0 = float((lift > 0).mean())\n",
    "prob_lift_gt_001 = float((lift > 0.01).mean())  # > 1pp absolute\n",
    "cred_int = (float(np.quantile(lift, 0.025)), float(np.quantile(lift, 0.975)))\n",
    "\n",
    "{\n",
    "    \"P(lift > 0)\": prob_lift_gt0,\n",
    "    \"P(lift > 1pp absolute)\": prob_lift_gt_001,\n",
    "    \"95%_credible_interval_lift\": cred_int\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4d9b7",
   "metadata": {},
   "source": [
    "## 6) Sequential testing (multiple peeks without lying to yourself)\n",
    "\n",
    "In practice, teams check results daily. If you stop “as soon as p < 0.05”, false positives explode.\n",
    "\n",
    "Two common fixes:\n",
    "\n",
    "### A) Frequentist group sequential testing\n",
    "Plan a small number of “looks” (e.g., day 7, 14, 21, 30) with stricter thresholds early.\n",
    "A simple option: **O'Brien-Fleming** boundaries.\n",
    "\n",
    "### B) Bayesian sequential monitoring\n",
    "Bayes updates are coherent under continuous monitoring. You choose a decision rule like:\n",
    "- Stop for success if P(lift > 0) ≥ 0.95\n",
    "- Stop for futility if P(lift > 0) ≤ 0.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de81f0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>look_frac</th>\n",
       "      <th>n</th>\n",
       "      <th>lift</th>\n",
       "      <th>z</th>\n",
       "      <th>z_crit_(OBF)</th>\n",
       "      <th>reject_at_this_look</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>12500</td>\n",
       "      <td>0.041542</td>\n",
       "      <td>5.918670</td>\n",
       "      <td>3.919928</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>25000</td>\n",
       "      <td>0.039829</td>\n",
       "      <td>7.992380</td>\n",
       "      <td>2.771808</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>37500</td>\n",
       "      <td>0.038692</td>\n",
       "      <td>9.498398</td>\n",
       "      <td>2.263171</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>10.014734</td>\n",
       "      <td>1.959964</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   look_frac      n      lift          z  z_crit_(OBF)  reject_at_this_look\n",
       "0       0.25  12500  0.041542   5.918670      3.919928                 True\n",
       "1       0.50  25000  0.039829   7.992380      2.771808                 True\n",
       "2       0.75  37500  0.038692   9.498398      2.263171                 True\n",
       "3       1.00  50000  0.035338  10.014734      1.959964                 True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll simulate interim looks by ordering users randomly (as if they arrived over time)\n",
    "d = df.sample(frac=1, random_state=7).reset_index(drop=True)\n",
    "\n",
    "looks = [0.25, 0.50, 0.75, 1.00]  # 4 looks\n",
    "alpha = 0.05\n",
    "\n",
    "def obrien_fleming_crit(alpha, t):\n",
    "    # approximate two-sided OBF boundary using normal quantiles\n",
    "    # critical z at information fraction t\n",
    "    z_alpha2 = stats.norm.ppf(1 - alpha/2)\n",
    "    return z_alpha2 / np.sqrt(t)\n",
    "\n",
    "results = []\n",
    "for frac in looks:\n",
    "    m = int(len(d)*frac)\n",
    "    dd = d.iloc[:m]\n",
    "    n_c_i = (dd.treatment==0).sum()\n",
    "    n_t_i = (dd.treatment==1).sum()\n",
    "    x_c_i = dd.loc[dd.treatment==0, \"ps5_purchase_30d\"].sum()\n",
    "    x_t_i = dd.loc[dd.treatment==1, \"ps5_purchase_30d\"].sum()\n",
    "\n",
    "    p_c_i = x_c_i/n_c_i\n",
    "    p_t_i = x_t_i/n_t_i\n",
    "    lift_i = p_t_i - p_c_i\n",
    "\n",
    "    p_pool_i = (x_c_i + x_t_i) / (n_c_i + n_t_i)\n",
    "    se_pool_i = np.sqrt(p_pool_i*(1-p_pool_i)*(1/n_c_i + 1/n_t_i))\n",
    "    z_i = lift_i / se_pool_i\n",
    "\n",
    "    z_crit = obrien_fleming_crit(alpha, frac)\n",
    "    reject = abs(z_i) >= z_crit\n",
    "\n",
    "    results.append({\n",
    "        \"look_frac\": frac,\n",
    "        \"n\": m,\n",
    "        \"lift\": lift_i,\n",
    "        \"z\": z_i,\n",
    "        \"z_crit_(OBF)\": z_crit,\n",
    "        \"reject_at_this_look\": reject\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4500754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>look_frac</th>\n",
       "      <th>n</th>\n",
       "      <th>P(lift&gt;0)</th>\n",
       "      <th>P(lift&gt;1pp)</th>\n",
       "      <th>success_stop_(&gt;=0.95)</th>\n",
       "      <th>futility_stop_(&lt;=0.10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>12500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>25000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>37500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   look_frac      n  P(lift>0)  P(lift>1pp)  success_stop_(>=0.95)  \\\n",
       "0       0.25  12500        1.0          1.0                   True   \n",
       "1       0.50  25000        1.0          1.0                   True   \n",
       "2       0.75  37500        1.0          1.0                   True   \n",
       "3       1.00  50000        1.0          1.0                   True   \n",
       "\n",
       "   futility_stop_(<=0.10)  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                   False  \n",
       "3                   False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian sequential monitoring using Beta-Binomial posteriors\n",
    "from scipy.stats import beta\n",
    "\n",
    "def bayes_prob_lift_gt0(dd, draws=60000, seed=123):\n",
    "    n_c = (dd.treatment==0).sum()\n",
    "    n_t = (dd.treatment==1).sum()\n",
    "    x_c = dd.loc[dd.treatment==0, \"ps5_purchase_30d\"].sum()\n",
    "    x_t = dd.loc[dd.treatment==1, \"ps5_purchase_30d\"].sum()\n",
    "    pc = beta.rvs(1+x_c, 1+(n_c-x_c), size=draws, random_state=seed)\n",
    "    pt = beta.rvs(1+x_t, 1+(n_t-x_t), size=draws, random_state=seed+1)\n",
    "    return float((pt-pc > 0).mean()), float((pt-pc > 0.01).mean())\n",
    "\n",
    "bayes_results = []\n",
    "for frac in looks:\n",
    "    m = int(len(d)*frac)\n",
    "    dd = d.iloc[:m]\n",
    "    p_gt0, p_gt1pp = bayes_prob_lift_gt0(dd)\n",
    "    bayes_results.append({\n",
    "        \"look_frac\": frac,\n",
    "        \"n\": m,\n",
    "        \"P(lift>0)\": p_gt0,\n",
    "        \"P(lift>1pp)\": p_gt1pp,\n",
    "        \"success_stop_(>=0.95)\": p_gt0 >= 0.95,\n",
    "        \"futility_stop_(<=0.10)\": p_gt0 <= 0.10\n",
    "    })\n",
    "\n",
    "pd.DataFrame(bayes_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3633db36",
   "metadata": {},
   "source": [
    "## 7) Heterogeneous effects (who responds?)\n",
    "\n",
    "A senior-level addition: quantify where the lift comes from.\n",
    "\n",
    "Here we do a simple segment cut (PS+ membership and spend tier).\n",
    "In real work you can extend this to uplift models / causal forests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5253f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>abs_lift</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_plus_member</th>\n",
       "      <th>spend_tier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>S1_low</th>\n",
       "      <td>0.164499</td>\n",
       "      <td>0.226961</td>\n",
       "      <td>0.062461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4_vhigh</th>\n",
       "      <td>0.206010</td>\n",
       "      <td>0.262057</td>\n",
       "      <td>0.056047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3_high</th>\n",
       "      <td>0.200644</td>\n",
       "      <td>0.251868</td>\n",
       "      <td>0.051224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2_mid</th>\n",
       "      <td>0.206101</td>\n",
       "      <td>0.255267</td>\n",
       "      <td>0.049165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>S2_mid</th>\n",
       "      <td>0.156806</td>\n",
       "      <td>0.186361</td>\n",
       "      <td>0.029555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1_low</th>\n",
       "      <td>0.140758</td>\n",
       "      <td>0.161836</td>\n",
       "      <td>0.021078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3_high</th>\n",
       "      <td>0.166184</td>\n",
       "      <td>0.182267</td>\n",
       "      <td>0.016083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4_vhigh</th>\n",
       "      <td>0.174412</td>\n",
       "      <td>0.185369</td>\n",
       "      <td>0.010957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "treatment                         0         1  abs_lift\n",
       "ps_plus_member spend_tier                              \n",
       "1              S1_low      0.164499  0.226961  0.062461\n",
       "               S4_vhigh    0.206010  0.262057  0.056047\n",
       "               S3_high     0.200644  0.251868  0.051224\n",
       "               S2_mid      0.206101  0.255267  0.049165\n",
       "0              S2_mid      0.156806  0.186361  0.029555\n",
       "               S1_low      0.140758  0.161836  0.021078\n",
       "               S3_high     0.166184  0.182267  0.016083\n",
       "               S4_vhigh    0.174412  0.185369  0.010957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = (df\n",
    "       .groupby([\"ps_plus_member\",\"spend_tier\",\"treatment\"])[\"ps5_purchase_30d\"]\n",
    "       .mean()\n",
    "       .unstack())\n",
    "seg[\"abs_lift\"] = seg[1] - seg[0]\n",
    "seg.sort_values(\"abs_lift\", ascending=False).head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3046f",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "- **Primary result (30-day PS5 conversion):**  \n",
    "  Control = **17.51%**, Treatment = **21.05%**, Lift = **+3.53 pp** (p < 1e-6, effectively ~0).\n",
    "\n",
    "- **Bayesian:**  \n",
    "  **P(lift > 0) = 1.00**, 95% credible interval = **[+2.84 pp, +4.22 pp]**.\n",
    "\n",
    "- **Revenue impact (60-day):**  \n",
    "  **+$9.51 per user** (CUPED-adjusted), 95% CI = **[$8.57, $10.45]**.\n",
    "\n",
    "- **Guardrails:**  \n",
    "  Unsubscribe **+0.31 pp**, Opt-out **+0.54 pp** (small increases; monitor against internal thresholds).\n",
    "\n",
    "- **Segments:**  \n",
    "  Strongest lift in **PS+ members with low spend (S1_low): +6.25 pp**.  \n",
    "  PS+ members across tiers also show strong lift (~+4.9 to +5.6 pp).\n",
    "\n",
    "- **Decision:**  \n",
    "  **Ship** with guardrail monitoring.  \n",
    "  **Next test:** Optimize messaging frequency/creative for non-PS+ users, and test incentive variants for PS+ low spend to maximize lift while controlling opt-outs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64228762",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
